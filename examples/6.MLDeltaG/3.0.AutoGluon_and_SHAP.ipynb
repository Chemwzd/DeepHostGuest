{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-01-10T04:48:29.782535Z",
     "start_time": "2026-01-10T04:48:28.344181Z"
    }
   },
   "source": [
    "# AutoGluon for Binding Free Energy Prediction\n",
    "import os\n",
    "import json\n",
    "import ast\n",
    "from itertools import product\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "from autogluon.tabular import TabularPredictor\n",
    "\n",
    "descriptor_excel = (\n",
    "    '/path/to/host_guest_features_SI.xlsx'\n",
    ")\n",
    "\n",
    "df = pd.read_excel(descriptor_excel, sheet_name='Features').reset_index(drop=True)\n",
    "\n",
    "ID = df['ID']\n",
    "y = df['deltaG']\n",
    "y_array = y.values\n",
    "ID_array = ID.values\n",
    "type_labels = df['Type'].astype(str).values\n",
    "\n",
    "shared_features = [\n",
    "    'GuestLogP', 'GuestTPSA', 'PoreDiameter', 'PoreVolume',\n",
    "    'GuestCavityRatio', 'HostMPI', 'GuestMPI',\n",
    "    'HostPositiveSA', 'HostNegativeSA', 'GuestPositiveSA', 'GuestNegativeSA',\n",
    "    'HostPolarSA', 'HostNonpolarSA', 'GuestPolarSA', 'GuestNonpolarSA',\n",
    "    'InteractionFP', 'ESPFitness',\n",
    "]\n",
    "\n",
    "\n",
    "def build_feature_matrix(df, fp_blocks, shared_features):\n",
    "    feature_cols = fp_blocks + shared_features\n",
    "    X_parts = []\n",
    "\n",
    "    for col in feature_cols:\n",
    "        if col not in df.columns:\n",
    "            raise KeyError(f\"Column '{col}' not found in DataFrame\")\n",
    "\n",
    "        s = df[col]\n",
    "        first_val = s.iloc[0]\n",
    "\n",
    "        if isinstance(first_val, (list, tuple, np.ndarray)):\n",
    "            m = pd.DataFrame(s.tolist(), index=df.index)\n",
    "            m = m.add_prefix(col + \"_\")\n",
    "            X_parts.append(m)\n",
    "            continue\n",
    "\n",
    "        if isinstance(first_val, str):\n",
    "            parsed_ok = False\n",
    "            try:\n",
    "                tmp = ast.literal_eval(first_val)\n",
    "                if isinstance(tmp, (list, tuple, np.ndarray)):\n",
    "                    seq_series = s.apply(\n",
    "                        lambda x: ast.literal_eval(x) if isinstance(x, str) else x\n",
    "                    )\n",
    "                    m = pd.DataFrame(seq_series.tolist(), index=df.index)\n",
    "                    m = m.add_prefix(col + \"_\")\n",
    "                    X_parts.append(m)\n",
    "                    parsed_ok = True\n",
    "            except (ValueError, SyntaxError):\n",
    "                parsed_ok = False\n",
    "\n",
    "            if parsed_ok:\n",
    "                continue\n",
    "        X_parts.append(s.to_frame())\n",
    "\n",
    "    X_feat = pd.concat(X_parts, axis=1)\n",
    "    return X_feat\n",
    "\n",
    "\n",
    "base_model_root = (\n",
    "    './AutoGluonModels'\n",
    ")\n",
    "\n",
    "os.makedirs(base_model_root, exist_ok=True)\n",
    "\n",
    "all_summary_records = []\n",
    "\n",
    "n_splits_outer = 5\n",
    "\n",
    "fp_blocks = ['HostMACCSKey', 'GuestMACCSKey']\n",
    "X_feat = build_feature_matrix(df, fp_blocks, shared_features)\n",
    "X_feat = X_feat.reset_index(drop=True)\n",
    "assert X_feat.shape[0] == len(df), \"Row count mismatch.\"\n",
    "\n",
    "print(X_feat.shape)\n",
    "train_data = X_feat.copy()\n",
    "train_data['deltaG'] = y\n",
    "print(X_feat.columns)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(876, 363)\n",
      "Index(['HostMACCSKey_0', 'HostMACCSKey_1', 'HostMACCSKey_2', 'HostMACCSKey_3',\n",
      "       'HostMACCSKey_4', 'HostMACCSKey_5', 'HostMACCSKey_6', 'HostMACCSKey_7',\n",
      "       'HostMACCSKey_8', 'HostMACCSKey_9',\n",
      "       ...\n",
      "       'InteractionFP_4', 'InteractionFP_5', 'InteractionFP_6',\n",
      "       'InteractionFP_7', 'InteractionFP_8', 'InteractionFP_9',\n",
      "       'InteractionFP_10', 'InteractionFP_11', 'InteractionFP_12',\n",
      "       'ESPFitness'],\n",
      "      dtype='object', length=363)\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-10T04:50:57.314184Z",
     "start_time": "2026-01-10T04:48:56.045952Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Feature Selection\n",
    "train_df = X_feat.copy()\n",
    "train_df['deltaG'] = y\n",
    "\n",
    "predictor_full = TabularPredictor(\n",
    "    label='deltaG',\n",
    "    problem_type='regression',\n",
    "    eval_metric='r2'\n",
    ").fit(\n",
    "    train_data=train_df,\n",
    "    presets='good_quality',\n",
    "    num_cpus=24,\n",
    "    num_gpus=0,\n",
    "    num_stack_levels=0,\n",
    "    auto_stack=False,\n",
    ")\n",
    "\n",
    "fi = predictor_full.feature_importance(train_df)\n",
    "fi_sorted = fi.sort_values('importance', ascending=False)\n",
    "fi_sorted = fi_sorted[fi_sorted['importance'] > 0]\n",
    "\n",
    "cum_importance = fi_sorted['importance'].cumsum() / fi_sorted['importance'].sum()\n",
    "selected_features = cum_importance[cum_importance <= 0.95].index.tolist()"
   ],
   "id": "3b40077856b18785",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20260110_044856\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.10.18\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #63~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Tue Apr 22 19:00:15 UTC 2\n",
      "CPU Count:          32\n",
      "Memory Avail:       80.17 GB / 94.10 GB (85.2%)\n",
      "Disk Space Avail:   837.70 GB / 3753.99 GB (22.3%)\n",
      "===================================================\n",
      "Presets specified: ['good_quality']\n",
      "Using hyperparameters preset: hyperparameters='light'\n",
      "Beginning AutoGluon training ... Time limit = 3600s\n",
      "AutoGluon will save models to \"/mnt/4TBStorage1/Desktop/Papers/HostGuestModel/HostGuestModel_DataFile/BindingPrediction/ver_SupraBank/MLDeltaG/MLDeltaGCodes/AutogluonModels/ag-20260110_044856\"\n",
      "Train Data Rows:    876\n",
      "Train Data Columns: 363\n",
      "Label Column:       deltaG\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    82094.89 MB\n",
      "\tTrain Data (Original)  Memory Usage: 2.43 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 266 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUseless Original Features (Count: 71): ['HostMACCSKey_0', 'HostMACCSKey_1', 'HostMACCSKey_2', 'HostMACCSKey_3', 'HostMACCSKey_4', 'HostMACCSKey_5', 'HostMACCSKey_6', 'HostMACCSKey_7', 'HostMACCSKey_8', 'HostMACCSKey_10', 'HostMACCSKey_11', 'HostMACCSKey_13', 'HostMACCSKey_14', 'HostMACCSKey_15', 'HostMACCSKey_16', 'HostMACCSKey_18', 'HostMACCSKey_19', 'HostMACCSKey_20', 'HostMACCSKey_21', 'HostMACCSKey_22', 'HostMACCSKey_23', 'HostMACCSKey_25', 'HostMACCSKey_27', 'HostMACCSKey_30', 'HostMACCSKey_31', 'HostMACCSKey_32', 'HostMACCSKey_33', 'HostMACCSKey_34', 'HostMACCSKey_35', 'HostMACCSKey_36', 'HostMACCSKey_41', 'HostMACCSKey_42', 'HostMACCSKey_43', 'HostMACCSKey_45', 'HostMACCSKey_46', 'HostMACCSKey_47', 'HostMACCSKey_53', 'HostMACCSKey_56', 'HostMACCSKey_63', 'HostMACCSKey_68', 'HostMACCSKey_86', 'HostMACCSKey_87', 'HostMACCSKey_103', 'HostMACCSKey_104', 'HostMACCSKey_107', 'HostMACCSKey_112', 'HostMACCSKey_134', 'HostMACCSKey_165', 'HostMACCSKey_166', 'GuestMACCSKey_0', 'GuestMACCSKey_1', 'GuestMACCSKey_2', 'GuestMACCSKey_3', 'GuestMACCSKey_4', 'GuestMACCSKey_5', 'GuestMACCSKey_6', 'GuestMACCSKey_7', 'GuestMACCSKey_9', 'GuestMACCSKey_10', 'GuestMACCSKey_12', 'GuestMACCSKey_13', 'GuestMACCSKey_14', 'GuestMACCSKey_16', 'GuestMACCSKey_18', 'GuestMACCSKey_21', 'GuestMACCSKey_35', 'GuestMACCSKey_44', 'GuestMACCSKey_68', 'GuestMACCSKey_166', 'InteractionFP_3', 'InteractionFP_8']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tUnused Original Features (Count: 45): ['HostMACCSKey_26', 'HostMACCSKey_40', 'HostMACCSKey_55', 'HostMACCSKey_58', 'HostMACCSKey_60', 'HostMACCSKey_61', 'HostMACCSKey_64', 'HostMACCSKey_67', 'HostMACCSKey_69', 'HostMACCSKey_70', 'HostMACCSKey_71', 'HostMACCSKey_73', 'HostMACCSKey_75', 'HostMACCSKey_76', 'HostMACCSKey_81', 'HostMACCSKey_88', 'HostMACCSKey_96', 'HostMACCSKey_99', 'HostMACCSKey_117', 'HostMACCSKey_119', 'HostMACCSKey_137', 'HostMACCSKey_142', 'HostMACCSKey_143', 'HostMACCSKey_144', 'HostMACCSKey_147', 'HostMACCSKey_151', 'HostMACCSKey_153', 'HostMACCSKey_159', 'HostMACCSKey_160', 'HostMACCSKey_161', 'HostMACCSKey_162', 'HostMACCSKey_163', 'HostMACCSKey_164', 'GuestMACCSKey_33', 'GuestMACCSKey_40', 'GuestMACCSKey_55', 'GuestMACCSKey_60', 'GuestMACCSKey_70', 'GuestMACCSKey_73', 'GuestMACCSKey_99', 'GuestMACCSKey_117', 'GuestMACCSKey_134', 'GuestMACCSKey_143', 'GuestMACCSKey_147', 'GuestMACCSKey_153']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('int', []) : 45 | ['HostMACCSKey_26', 'HostMACCSKey_40', 'HostMACCSKey_55', 'HostMACCSKey_58', 'HostMACCSKey_60', ...]\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) :  16 | ['GuestLogP', 'GuestTPSA', 'PoreDiameter', 'PoreVolume', 'GuestCavityRatio', ...]\n",
      "\t\t('int', [])   : 231 | ['HostMACCSKey_9', 'HostMACCSKey_12', 'HostMACCSKey_17', 'HostMACCSKey_24', 'HostMACCSKey_28', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     :  16 | ['GuestLogP', 'GuestTPSA', 'PoreDiameter', 'PoreVolume', 'GuestCavityRatio', ...]\n",
      "\t\t('int', [])       :  10 | ['InteractionFP_0', 'InteractionFP_1', 'InteractionFP_2', 'InteractionFP_4', 'InteractionFP_5', ...]\n",
      "\t\t('int', ['bool']) : 221 | ['HostMACCSKey_9', 'HostMACCSKey_12', 'HostMACCSKey_17', 'HostMACCSKey_24', 'HostMACCSKey_28', ...]\n",
      "\t1.4s = Fit runtime\n",
      "\t247 features in original data used to generate 247 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.36 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 1.37s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'r2'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 700, Val Rows: 176\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}],\n",
      "\t'XGB': [{}],\n",
      "\t'FASTAI': [{}],\n",
      "\t'RF': [{'criterion': 'gini', 'max_depth': 15, 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'max_depth': 15, 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'max_depth': 15, 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'max_depth': 15, 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'max_depth': 15, 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'max_depth': 15, 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "}\n",
      "Fitting 9 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT ... Training model for up to 3598.63s of the 3598.63s of remaining time.\n",
      "\tFitting with cpus=24, gpus=0, mem=0.0/80.1 GB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's l2: 1.50075\tvalid_set's r2: 0.805408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t0.806\t = Validation score   (r2)\n",
      "\t3.31s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBM ... Training model for up to 3595.30s of the 3595.30s of remaining time.\n",
      "\tFitting with cpus=24, gpus=0, mem=0.0/80.1 GB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's l2: 1.76815\tvalid_set's r2: 0.770735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t0.7708\t = Validation score   (r2)\n",
      "\t5.36s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ... Training model for up to 3589.92s of the 3589.92s of remaining time.\n",
      "\tFitting with cpus=24, gpus=0\n",
      "\t0.7172\t = Validation score   (r2)\n",
      "\t0.35s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: CatBoost ... Training model for up to 3589.51s of the 3589.51s of remaining time.\n",
      "\tFitting with cpus=24, gpus=0\n",
      "\t0.7854\t = Validation score   (r2)\n",
      "\t28.59s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE ... Training model for up to 3560.89s of the 3560.89s of remaining time.\n",
      "\tFitting with cpus=24, gpus=0\n",
      "\t0.7751\t = Validation score   (r2)\n",
      "\t0.3s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ... Training model for up to 3560.54s of the 3560.54s of remaining time.\n",
      "\tFitting with cpus=24, gpus=0, mem=0.0/79.7 GB\n",
      "\t0.74\t = Validation score   (r2)\n",
      "\t2.11s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: XGBoost ... Training model for up to 3558.41s of the 3558.41s of remaining time.\n",
      "\tFitting with cpus=24, gpus=0\n",
      "\t0.7353\t = Validation score   (r2)\n",
      "\t0.92s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ... Training model for up to 3557.46s of the 3557.46s of remaining time.\n",
      "\tFitting with cpus=24, gpus=0, mem=0.0/79.4 GB\n",
      "/home/rtx4090/anaconda3/envs/autogluon/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "\t0.7814\t = Validation score   (r2)\n",
      "\t8.62s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ... Training model for up to 3548.83s of the 3548.83s of remaining time.\n",
      "\tFitting with cpus=24, gpus=0, mem=0.2/79.4 GB\n",
      "\t0.7255\t = Validation score   (r2)\n",
      "\t9.51s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.00s of the 3539.30s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBMXT': 0.438, 'NeuralNetTorch': 0.25, 'CatBoost': 0.125, 'NeuralNetFastAI': 0.125, 'XGBoost': 0.062}\n",
      "\t0.8163\t = Validation score   (r2)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 60.73s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 4953.8 rows/s (176 batch size)\n",
      "Automatically performing refit_full as a post-fit operation (due to `.fit(..., refit_full=True)`\n",
      "Refitting models via `predictor.refit_full` using all of the data (combined train and validation)...\n",
      "\tModels trained in this way will have the suffix \"_FULL\" and have NaN validation score.\n",
      "\tThis process is not bound by time_limit, but should take less time than the original `predictor.fit` call.\n",
      "\tTo learn more, refer to the `.refit_full` method docstring which explains how \"_FULL\" models differ from normal models.\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_FULL ...\n",
      "\tFitting with cpus=24, gpus=0, mem=0.0/79.4 GB\n",
      "\t2.9s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBM_FULL ...\n",
      "\tFitting with cpus=24, gpus=0, mem=0.0/79.3 GB\n",
      "\t4.17s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: RandomForestMSE_FULL ...\n",
      "\tFitting with cpus=24, gpus=0\n",
      "\t0.34s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: CatBoost_FULL ...\n",
      "\tFitting with cpus=24, gpus=0\n",
      "\t17.87s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: ExtraTreesMSE_FULL ...\n",
      "\tFitting with cpus=24, gpus=0\n",
      "\t0.29s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_FULL ...\n",
      "\tFitting with cpus=24, gpus=0, mem=0.0/79.2 GB\n",
      "\tStopping at the best epoch learned earlier - 15.\n",
      "\t0.33s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: XGBoost_FULL ...\n",
      "\tFitting with cpus=24, gpus=0\n",
      "\t0.43s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetTorch_FULL ...\n",
      "\tFitting with cpus=24, gpus=0, mem=0.0/79.2 GB\n",
      "/home/rtx4090/anaconda3/envs/autogluon/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "\t5.97s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMLarge_FULL ...\n",
      "\tFitting with cpus=24, gpus=0, mem=0.2/79.2 GB\n",
      "\t5.95s\t = Training   runtime\n",
      "Fitting model: WeightedEnsemble_L2_FULL | Skipping fit via cloning parent ...\n",
      "\tEnsemble Weights: {'LightGBMXT': 0.438, 'NeuralNetTorch': 0.25, 'CatBoost': 0.125, 'NeuralNetFastAI': 0.125, 'XGBoost': 0.062}\n",
      "\t0.02s\t = Training   runtime\n",
      "Updated best model to \"WeightedEnsemble_L2_FULL\" (Previously \"WeightedEnsemble_L2\"). AutoGluon will default to using \"WeightedEnsemble_L2_FULL\" for predict() and predict_proba().\n",
      "Refit complete, total runtime = 38.54s ... Best model: \"WeightedEnsemble_L2_FULL\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/mnt/4TBStorage1/Desktop/Papers/HostGuestModel/HostGuestModel_DataFile/BindingPrediction/ver_SupraBank/MLDeltaG/MLDeltaGCodes/AutogluonModels/ag-20260110_044856\")\n",
      "These features in provided data are not utilized by the predictor and will be ignored: ['HostMACCSKey_0', 'HostMACCSKey_1', 'HostMACCSKey_2', 'HostMACCSKey_3', 'HostMACCSKey_4', 'HostMACCSKey_5', 'HostMACCSKey_6', 'HostMACCSKey_7', 'HostMACCSKey_8', 'HostMACCSKey_10', 'HostMACCSKey_11', 'HostMACCSKey_13', 'HostMACCSKey_14', 'HostMACCSKey_15', 'HostMACCSKey_16', 'HostMACCSKey_18', 'HostMACCSKey_19', 'HostMACCSKey_20', 'HostMACCSKey_21', 'HostMACCSKey_22', 'HostMACCSKey_23', 'HostMACCSKey_25', 'HostMACCSKey_26', 'HostMACCSKey_27', 'HostMACCSKey_30', 'HostMACCSKey_31', 'HostMACCSKey_32', 'HostMACCSKey_33', 'HostMACCSKey_34', 'HostMACCSKey_35', 'HostMACCSKey_36', 'HostMACCSKey_40', 'HostMACCSKey_41', 'HostMACCSKey_42', 'HostMACCSKey_43', 'HostMACCSKey_45', 'HostMACCSKey_46', 'HostMACCSKey_47', 'HostMACCSKey_53', 'HostMACCSKey_55', 'HostMACCSKey_56', 'HostMACCSKey_58', 'HostMACCSKey_60', 'HostMACCSKey_61', 'HostMACCSKey_63', 'HostMACCSKey_64', 'HostMACCSKey_67', 'HostMACCSKey_68', 'HostMACCSKey_69', 'HostMACCSKey_70', 'HostMACCSKey_71', 'HostMACCSKey_73', 'HostMACCSKey_75', 'HostMACCSKey_76', 'HostMACCSKey_81', 'HostMACCSKey_86', 'HostMACCSKey_87', 'HostMACCSKey_88', 'HostMACCSKey_96', 'HostMACCSKey_99', 'HostMACCSKey_103', 'HostMACCSKey_104', 'HostMACCSKey_107', 'HostMACCSKey_112', 'HostMACCSKey_117', 'HostMACCSKey_119', 'HostMACCSKey_134', 'HostMACCSKey_137', 'HostMACCSKey_142', 'HostMACCSKey_143', 'HostMACCSKey_144', 'HostMACCSKey_147', 'HostMACCSKey_151', 'HostMACCSKey_153', 'HostMACCSKey_159', 'HostMACCSKey_160', 'HostMACCSKey_161', 'HostMACCSKey_162', 'HostMACCSKey_163', 'HostMACCSKey_164', 'HostMACCSKey_165', 'HostMACCSKey_166', 'GuestMACCSKey_0', 'GuestMACCSKey_1', 'GuestMACCSKey_2', 'GuestMACCSKey_3', 'GuestMACCSKey_4', 'GuestMACCSKey_5', 'GuestMACCSKey_6', 'GuestMACCSKey_7', 'GuestMACCSKey_9', 'GuestMACCSKey_10', 'GuestMACCSKey_12', 'GuestMACCSKey_13', 'GuestMACCSKey_14', 'GuestMACCSKey_16', 'GuestMACCSKey_18', 'GuestMACCSKey_21', 'GuestMACCSKey_33', 'GuestMACCSKey_35', 'GuestMACCSKey_40', 'GuestMACCSKey_44', 'GuestMACCSKey_55', 'GuestMACCSKey_60', 'GuestMACCSKey_68', 'GuestMACCSKey_70', 'GuestMACCSKey_73', 'GuestMACCSKey_99', 'GuestMACCSKey_117', 'GuestMACCSKey_134', 'GuestMACCSKey_143', 'GuestMACCSKey_147', 'GuestMACCSKey_153', 'GuestMACCSKey_166', 'InteractionFP_3', 'InteractionFP_8']\n",
      "Computing feature importance via permutation shuffling for 247 features using 876 rows with 5 shuffle sets...\n",
      "\t95.94s\t= Expected runtime (19.19s per shuffle set)\n",
      "\t21.74s\t= Actual runtime (Completed 5 of 5 shuffle sets)\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-10T04:51:03.651029Z",
     "start_time": "2026-01-10T04:51:03.648935Z"
    }
   },
   "cell_type": "code",
   "source": "print(f\"Selected {len(selected_features)} features out of {X_feat.shape[1]}\")",
   "id": "b8556094fa5dc00",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected 101 features out of 363\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "all_summary_records = []\n",
    "\n",
    "n_splits_outer = 5\n",
    "\n",
    "skf = StratifiedKFold(\n",
    "    n_splits=n_splits_outer,\n",
    "    shuffle=True,\n",
    "    random_state=1000\n",
    ")\n",
    "\n",
    "selected_X_feat = X_feat.copy()\n",
    "for feat in selected_X_feat.columns:\n",
    "    if feat not in selected_features:\n",
    "        selected_X_feat = selected_X_feat.drop([feat], axis=1)\n",
    "\n",
    "print(f'Shape of selected_feat: {selected_X_feat.shape}')\n",
    "\n",
    "model_root_path = os.path.join(base_model_root, '101Features_good_5bag_5fold')\n",
    "os.makedirs(model_root_path, exist_ok=True)\n",
    "\n",
    "with open(os.path.join(model_root_path, 'selected_features.txt'), 'w') as f:\n",
    "    f.writelines('\\n'.join(selected_features))\n",
    "\n",
    "kf_results = {}\n",
    "excel_out = os.path.join(model_root_path, 'PredictionResults_5fold.xlsx')\n",
    "if os.path.exists(excel_out):\n",
    "    print(f'{model_root_path} has already been trained.')\n",
    "    quit()\n",
    "\n",
    "type_labels = df['Type'].astype(str).values\n",
    "\n",
    "ID = df['ID']\n",
    "y = df['deltaG']\n",
    "y_array = y.values\n",
    "ID_array = ID.values\n",
    "\n",
    "# ========== 5-fold==========\n",
    "for fold, (train_idx, test_idx) in enumerate(skf.split(selected_X_feat, type_labels), start=1):\n",
    "    print(f\"\\n===== Training fold {fold} / {n_splits_outer} =====\")\n",
    "\n",
    "    X_train = selected_X_feat.iloc[train_idx].copy()\n",
    "    X_test = selected_X_feat.iloc[test_idx].copy()\n",
    "    y_train = y_array[train_idx]\n",
    "    y_test = y_array[test_idx]\n",
    "    id_train = ID_array[train_idx]\n",
    "    id_test = ID_array[test_idx]\n",
    "\n",
    "    train_data = X_train.copy()\n",
    "    print(f'shape of train_data: {train_data.shape}')\n",
    "    train_data['deltaG'] = y_train\n",
    "\n",
    "    test_data = X_test.copy()\n",
    "    test_data['deltaG'] = y_test\n",
    "\n",
    "    fold_model_path = os.path.join(model_root_path, f'Fold{fold}')\n",
    "    os.makedirs(fold_model_path, exist_ok=True)\n",
    "\n",
    "    predictor = TabularPredictor(\n",
    "        label='deltaG',\n",
    "        path=fold_model_path,\n",
    "        problem_type='regression',\n",
    "        eval_metric='r2'\n",
    "    ).fit(\n",
    "        train_data=train_data,\n",
    "        num_cpus=24,\n",
    "        num_gpus=0,\n",
    "        num_stack_levels=0,\n",
    "        auto_stack=False,\n",
    "        presets='good_quality',\n",
    "        num_bag_folds=5,\n",
    "    )\n",
    "\n",
    "    y_train_pred = predictor.predict(train_data.drop(columns=['deltaG']))\n",
    "    y_test_pred = predictor.predict(test_data.drop(columns=['deltaG']))\n",
    "\n",
    "    train_rmse = mean_squared_error(y_train, y_train_pred) ** 0.5\n",
    "    train_mae = mean_absolute_error(y_train, y_train_pred)\n",
    "    train_r2 = r2_score(y_train, y_train_pred)\n",
    "    train_r, _ = pearsonr(y_train, y_train_pred)\n",
    "\n",
    "    test_rmse = mean_squared_error(y_test, y_test_pred) ** 0.5\n",
    "    test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "    test_r2 = r2_score(y_test, y_test_pred)\n",
    "    test_r, _ = pearsonr(y_test, y_test_pred)\n",
    "\n",
    "    kf_results[fold] = {\n",
    "        'Model': f'Fold_{fold}',\n",
    "        'Train_RMSE': float(train_rmse),\n",
    "        'Train_MAE': float(train_mae),\n",
    "        'Train_R2': float(train_r2),\n",
    "        'Train_PearsonR': float(train_r),\n",
    "        'Test_RMSE': float(test_rmse),\n",
    "        'Test_MAE': float(test_mae),\n",
    "        'Test_R2': float(test_r2),\n",
    "        'Test_PearsonR': float(test_r),\n",
    "    }\n",
    "\n",
    "    print(f\"Fold {fold}: Train_R2 = {train_r2:.3f}, Test_R2 = {test_r2:.3f}, \"\n",
    "          f\"Train_RMSE = {train_rmse:.3f}, Test_RMSE = {test_rmse:.3f}\")\n",
    "\n",
    "    train_result = pd.DataFrame({\n",
    "        'ID': id_train,\n",
    "        'True_deltaG': y_train,\n",
    "        'Pred_deltaG': y_train_pred\n",
    "    })\n",
    "    test_result = pd.DataFrame({\n",
    "        'ID': id_test,\n",
    "        'True_deltaG': y_test,\n",
    "        'Pred_deltaG': y_test_pred\n",
    "    })\n",
    "\n",
    "    mode = 'w' if (not os.path.exists(excel_out) and fold == 1) else 'a'\n",
    "    with pd.ExcelWriter(excel_out, engine='openpyxl', mode=mode) as writer:\n",
    "        train_result.to_excel(writer, sheet_name=f'train_fold{fold}', index=False)\n",
    "        test_result.to_excel(writer, sheet_name=f'test_fold{fold}', index=False)\n",
    "\n",
    "json_out = os.path.join(model_root_path, 'TrainingResults_5fold.json')\n",
    "with open(json_out, 'w') as f:\n",
    "    json.dump(kf_results, f, indent=2)"
   ],
   "id": "2c32e09ca71b5f00",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# SHAP Analysis in each fold\n",
    "import os\n",
    "import json\n",
    "\n",
    "import shap\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from autogluon.tabular import TabularPredictor\n",
    "\n",
    "model_root_path = (\n",
    "    './AutoGluonModels/101Features_good_5bag_5fold'\n",
    ")\n",
    "\n",
    "n_splits_outer = 5\n",
    "\n",
    "skf = StratifiedKFold(\n",
    "    n_splits=n_splits_outer,\n",
    "    shuffle=True,\n",
    "    random_state=1000\n",
    ")\n",
    "\n",
    "print(f'Shape of selected_feat: {selected_X_feat.shape}')\n",
    "\n",
    "type_labels = df['Type'].astype(str).values\n",
    "\n",
    "max_display = 10\n",
    "\n",
    "# ========= 2. 5-fold SHAP Analysis =========\n",
    "for fold, (train_idx, test_idx) in enumerate(skf.split(selected_X_feat, type_labels), start=1):\n",
    "    fold_id = fold\n",
    "    print(f\"\\n===== SHAP for Fold {fold_id} =====\")\n",
    "\n",
    "    fold_model_path = os.path.join(model_root_path, f'Fold{fold_id}')\n",
    "    predictor_bs = TabularPredictor.load(fold_model_path)\n",
    "\n",
    "\n",
    "    shap_dir = os.path.join(fold_model_path, \"SHAP\")\n",
    "    os.makedirs(shap_dir, exist_ok=True)\n",
    "\n",
    "    X_train = selected_X_feat.iloc[train_idx].copy()\n",
    "    X_test = selected_X_feat.iloc[test_idx].copy()\n",
    "    y_train = y_array[train_idx]\n",
    "    y_test = y_array[test_idx]\n",
    "    id_train = ID_array[train_idx]\n",
    "    id_test = ID_array[test_idx]\n",
    "\n",
    "    train_data = X_train.copy()\n",
    "    train_data['deltaG'] = y_train\n",
    "    test_data = X_test.copy()\n",
    "    test_data['deltaG'] = y_test\n",
    "\n",
    "    leaderboard = predictor_bs.leaderboard(test_data, silent=True)\n",
    "\n",
    "    X_bg = X_train.sample(n=min(200, len(X_train)), random_state=fold_id)\n",
    "    X_explain = X_test\n",
    "    feature_names = list(X_train.columns)\n",
    "\n",
    "    def model_predict(x):\n",
    "        if isinstance(x, pd.DataFrame):\n",
    "            df_in = x.copy()\n",
    "        else:\n",
    "            df_in = pd.DataFrame(x, columns=feature_names)\n",
    "        return predictor_bs.predict(df_in).to_numpy()\n",
    "\n",
    "\n",
    "    explainer = shap.Explainer(\n",
    "        model_predict,\n",
    "        X_bg,\n",
    "        seed=1000,\n",
    "        feature_names=feature_names\n",
    "    )\n",
    "\n",
    "\n",
    "    n_features = X_bg.shape[1]\n",
    "    shap_values = explainer(X_explain, max_evals=2 * n_features + 1)\n",
    "    shap_array = shap_values.values  # (n_samples, n_features)\n",
    "    feat_names = shap_values.feature_names\n",
    "\n",
    "    np.save(\n",
    "        os.path.join(shap_dir, f\"shap_values_fold{fold_id}.npy\"),\n",
    "        shap_array\n",
    "    )\n",
    "    X_explain.to_parquet(\n",
    "        os.path.join(shap_dir, f\"X_explain_fold{fold_id}.parquet\")\n",
    "    )\n",
    "\n",
    "    mean_abs = np.mean(np.abs(shap_array), axis=0)\n",
    "    shap_importance = (\n",
    "        pd.DataFrame({\"feature\": feat_names,\n",
    "                      \"mean_abs_shap\": mean_abs})\n",
    "        .sort_values(\"mean_abs_shap\", ascending=False)\n",
    "    )\n",
    "\n",
    "    shap_importance.to_excel(\n",
    "        os.path.join(shap_dir, f\"SHAP_importance_fold{fold_id}.xlsx\"),\n",
    "        index=False\n",
    "    )\n",
    "\n",
    "\n",
    "    pd.DataFrame({\"ID\": id_test}).to_excel(\n",
    "        os.path.join(shap_dir, f\"Test_IDs_fold{fold_id}.xlsx\"),\n",
    "        index=False\n",
    "    )\n",
    "\n",
    "    plt.figure()\n",
    "    shap.summary_plot(\n",
    "        shap_array,\n",
    "        X_explain,\n",
    "        feature_names=feat_names,\n",
    "        max_display=max_display,\n",
    "        show=False\n",
    "    )\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\n",
    "        os.path.join(shap_dir, f\"SHAP_summary_fold{fold_id}.png\"),\n",
    "        dpi=300,\n",
    "        bbox_inches='tight'\n",
    "    )\n",
    "    plt.close()\n",
    "\n",
    "    topN = max_display\n",
    "    shap_bar_df = shap_importance.head(topN).iloc[::-1]\n",
    "\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    plt.barh(\n",
    "        shap_bar_df['feature'],\n",
    "        shap_bar_df['mean_abs_shap']\n",
    "    )\n",
    "    plt.xlabel(\"Mean(|SHAP value|)\")\n",
    "    plt.title(f\"SHAP Feature Importance (Fold {fold_id})\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\n",
    "        os.path.join(shap_dir, f\"SHAP_barplot_fold{fold_id}.png\"),\n",
    "        dpi=300,\n",
    "        bbox_inches=\"tight\"\n",
    "    )\n",
    "    plt.close()\n",
    "\n",
    "    print(f\"Fold {fold_id}: SHAP arrays & importance saved to {shap_dir}\")"
   ],
   "id": "7ac33e036d491520",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# SHAP Analysis for out-of fold\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model_root_path = (\n",
    "    './AutoGluonModels/101Features_good_5bag_5fold'\n",
    ")\n",
    "\n",
    "fold_ids = [1, 2, 3, 4, 5]\n",
    "\n",
    "all_shap = []\n",
    "all_X = []\n",
    "\n",
    "for fid in fold_ids:\n",
    "    shap_dir = os.path.join(model_root_path, f'Fold{fid}', 'SHAP')\n",
    "\n",
    "    shap_path = os.path.join(shap_dir, f\"shap_values_fold{fid}.npy\")\n",
    "    X_path = os.path.join(shap_dir, f\"X_explain_fold{fid}.parquet\")\n",
    "\n",
    "    shap_array = np.load(shap_path)  # (n_val_fold, n_features)\n",
    "    X_explain_fold = pd.read_parquet(X_path)\n",
    "\n",
    "    all_shap.append(shap_array)\n",
    "    all_X.append(X_explain_fold)\n",
    "\n",
    "\n",
    "shap_values_cv = np.vstack(all_shap)  # (N_total, n_features)\n",
    "X_cv = pd.concat(all_X, axis=0, ignore_index=True)\n",
    "assert shap_values_cv.shape[0] == X_cv.shape[0]\n",
    "assert shap_values_cv.shape[1] == X_cv.shape[1]\n",
    "\n",
    "feature_names = list(X_cv.columns)\n",
    "\n",
    "max_display = 10\n",
    "\n",
    "print(\"shap_values_cv shape:\", shap_values_cv.shape)\n",
    "print(\"X_cv shape:\", X_cv.shape)\n",
    "\n",
    "#SHAP summary（beeswarm）\n",
    "plt.figure()\n",
    "shap.summary_plot(\n",
    "    shap_values_cv,\n",
    "    X_cv,\n",
    "    feature_names=feature_names,\n",
    "    max_display=max_display,\n",
    "    show=False\n",
    ")\n",
    "plt.tight_layout()\n",
    "out_png = os.path.join(model_root_path, f\"SHAP_summary_5fold_beeswarm.png\")\n",
    "plt.savefig(out_png, dpi=300, bbox_inches='tight', transparent=True)\n",
    "plt.close()\n",
    "\n",
    "print(\"Saved 5-fold SHAP summary beeswarm to:\", out_png)\n",
    "\n",
    "#SAHP bar summary\n",
    "plt.figure()\n",
    "shap.summary_plot(\n",
    "    shap_values_cv,\n",
    "    X_cv,\n",
    "    feature_names=feature_names,\n",
    "    max_display=max_display,\n",
    "    plot_type=\"bar\",\n",
    "    show=False\n",
    ")\n",
    "plt.tight_layout()\n",
    "out_png_bar = os.path.join(model_root_path, f\"SHAP_summary_5fold_bar.png\")\n",
    "plt.savefig(out_png_bar, dpi=300, bbox_inches='tight', transparent=True)\n",
    "plt.close()\n",
    "\n",
    "print(\"Saved 5-fold SHAP summary bar to:\", out_png_bar)\n"
   ],
   "id": "e35f180ceb16203d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-05T02:13:09.629116Z",
     "start_time": "2026-01-05T02:13:09.371105Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Global SHAP importance+beewarm\n",
    "\n",
    "def convert_rgb_color(x, y, z):\n",
    "    return (x/255, y/255, z/255)\n",
    "\n",
    "max_display = 10\n",
    "\n",
    "mean_abs_shap = np.abs(shap_values_cv).mean(axis=0)  # shape: (n_features,)\n",
    "sorted_idx = np.argsort(mean_abs_shap)[::-1]\n",
    "top_idx = sorted_idx[:max_display]\n",
    "\n",
    "top_features = [feature_names[i] for i in top_idx]\n",
    "top_importance = mean_abs_shap[top_idx]\n",
    "\n",
    "shap_top = shap_values_cv[:, top_idx]\n",
    "X_top = X_cv[top_features]\n",
    "\n",
    "feature_type_map = {\n",
    "    # host-level\n",
    "    \"HostNonpolarSA\": \"host\",\n",
    "    \"HostMPI\": \"host\",\n",
    "    \"HostPositiveSA\": \"host\",\n",
    "    \"HostPolarSA\": \"host\",\n",
    "    # guest-level\n",
    "    \"GuestLogP\": \"guest\",\n",
    "    \"GuestMACCSKey_49\": \"guest\",\n",
    "    \"GuestMACCSKey_128\": \"guest\",\n",
    "    \"GuestNegativeSA\": \"guest\",\n",
    "    # complex-level\n",
    "    \"InteractionFP_5\": \"complex\",\n",
    "    \"GuestCavityRatio\": \"complex\",\n",
    "}\n",
    "\n",
    "type_color_map = {\n",
    "    \"host\":    convert_rgb_color(230,111,81),\n",
    "    \"guest\":   convert_rgb_color(233,196,107),\n",
    "    \"complex\": convert_rgb_color(138,176,125),\n",
    "    \"other\":   \"#7f7f7f\",\n",
    "}\n",
    "\n",
    "bar_colors = []\n",
    "for f in top_features:\n",
    "    ftype = feature_type_map.get(f, \"other\")\n",
    "    bar_colors.append(type_color_map[ftype])\n",
    "\n",
    "plt.rcParams.update({\n",
    "    \"font.size\": 9,\n",
    "    \"axes.labelsize\": 9,\n",
    "    \"axes.titlesize\": 9,\n",
    "    \"xtick.labelsize\": 8,\n",
    "    \"ytick.labelsize\": 8,\n",
    "    \"legend.fontsize\": 8,\n",
    "})\n",
    "\n",
    "fig, axes = plt.subplots(\n",
    "    1, 2,\n",
    "    figsize=(18, 5),\n",
    "    gridspec_kw={\"width_ratios\": [3.2, 3]},\n",
    "    dpi=300\n",
    ")\n",
    "\n",
    "ax_bar = axes[0]\n",
    "top_importance_plot = top_importance[::-1]\n",
    "top_features_plot = top_features[::-1]\n",
    "bar_colors_plot = bar_colors[::-1]\n",
    "y_pos_plot = np.arange(len(top_features_plot))\n",
    "\n",
    "face_colors = [(*c, 0.7) for c in bar_colors_plot]\n",
    "\n",
    "bars = ax_bar.barh(\n",
    "    y_pos_plot,\n",
    "    top_importance_plot,\n",
    "    color=face_colors,\n",
    "    edgecolor=\"black\",\n",
    "    linewidth=0.8,\n",
    ")\n",
    "\n",
    "ax_bar.set_yticks(y_pos_plot)\n",
    "ax_bar.set_yticklabels(top_features_plot)\n",
    "ax_bar.set_xlabel(\"mean(|SHAP value|)\")\n",
    "ax_bar.set_title(\"Feature importance\")\n",
    "\n",
    "from matplotlib.patches import Patch\n",
    "\n",
    "ax_bee = axes[1]\n",
    "plt.sca(ax_bee)\n",
    "\n",
    "shap.summary_plot(\n",
    "    shap_top,\n",
    "    X_top,\n",
    "    feature_names=top_features,\n",
    "    max_display=max_display,\n",
    "    sort=False,\n",
    "    show=False,\n",
    "    # alpha=0.6,\n",
    "    cmap=\"coolwarm\"\n",
    ")\n",
    "ax_bee.set_title(\"Feature impact on ΔG\")\n",
    "ax_bar.spines[\"top\"].set_visible(False)\n",
    "ax_bar.spines[\"right\"].set_visible(False)\n",
    "ax_bar.spines[\"left\"].set_visible(True)\n",
    "ax_bar.spines[\"bottom\"].set_visible(True)\n",
    "\n",
    "ax_bee.set_yticklabels([])\n",
    "ax_bee.set_ylabel(\"\")\n",
    "ax_bee.tick_params(axis=\"y\", length=0)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "out_joint = os.path.join(\n",
    "    model_root_path,\n",
    "    f\"SHAP_5fold_importance_beeswarm.png\"\n",
    ")\n",
    "fig.savefig(out_joint, dpi=300, bbox_inches=\"tight\", transparent=False)\n",
    "plt.close(fig)\n",
    "\n",
    "print(\"Saved joint importance + beeswarm figure to:\", out_joint)\n"
   ],
   "id": "fc2c4d7105277961",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved joint importance + beeswarm figure to: /mnt/4TBStorage1/Desktop/Papers/HostGuestModel/HostGuestModel_DataFile/BindingPrediction/ver_SupraBank/MLDeltaG/Training/Cleared3/AutoGluonModels_FineTune_MACCSKey/101Features_good_5bag_5fold_noSolvent/SHAP_5fold_importance_beeswarm_top10.png\n"
     ]
    }
   ],
   "execution_count": 51
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-05T02:13:59.891626Z",
     "start_time": "2026-01-05T02:13:58.312518Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Local SHAP Analysis for Each Host Type\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model_root_path = (\n",
    "    './AutoGluonModels/101Features_good_5bag_5fold'\n",
    ")\n",
    "\n",
    "fold_ids = [1, 2, 3, 4, 5]\n",
    "\n",
    "descriptor_excel = (\n",
    "    './host_guest_features_SI.xlsx'\n",
    ")\n",
    "\n",
    "df_all = pd.read_excel(descriptor_excel, sheet_name='Features').reset_index(drop=True)\n",
    "id2type = df_all.set_index('ID')['Type'].astype(str).to_dict()\n",
    "\n",
    "all_shap = []\n",
    "all_X = []\n",
    "all_type = []\n",
    "\n",
    "for fid in fold_ids:\n",
    "    shap_dir = os.path.join(model_root_path, f'Fold{fid}', 'SHAP')\n",
    "\n",
    "    shap_path = os.path.join(shap_dir, f\"shap_values_fold{fid}.npy\")\n",
    "    X_path = os.path.join(shap_dir, f\"X_explain_fold{fid}.parquet\")\n",
    "    shap_array = np.load(shap_path)  # (n_val_fold, n_features)\n",
    "    X_explain_fold = pd.read_parquet(X_path)  # (n_val_fold, n_features)\n",
    "\n",
    "    ids_path = os.path.join(shap_dir, f\"Test_IDs_fold{fid}.xlsx\")\n",
    "    ids_fold = pd.read_excel(ids_path)['ID'].tolist()\n",
    "    assert len(ids_fold) == shap_array.shape[0] == X_explain_fold.shape[0]\n",
    "\n",
    "    types_fold = [id2type[i] for i in ids_fold]\n",
    "    all_shap.append(shap_array)\n",
    "    all_X.append(X_explain_fold)\n",
    "    all_type.extend(types_fold)\n",
    "\n",
    "shap_values_cv = np.vstack(all_shap)  # (N_total, n_features)\n",
    "X_cv = pd.concat(all_X, axis=0, ignore_index=True)\n",
    "type_cv = np.array(all_type)  # (N_total,)\n",
    "assert shap_values_cv.shape[0] == X_cv.shape[0] == len(type_cv)\n",
    "assert shap_values_cv.shape[1] == X_cv.shape[1]\n",
    "\n",
    "feature_names = list(X_cv.columns)\n",
    "\n",
    "print(\"Total samples:\", X_cv.shape[0])\n",
    "print(\"Num features (with PCA):\", X_cv.shape[1])\n",
    "\n",
    "out_root = os.path.join(model_root_path, \"SHAP_ByHostType\")\n",
    "os.makedirs(out_root, exist_ok=True)\n",
    "\n",
    "host_types = sorted(np.unique(type_cv))\n",
    "print(\"Host types:\", host_types)\n",
    "\n",
    "topN = 5\n",
    "\n",
    "for htype in host_types:\n",
    "    mask = (type_cv == htype)\n",
    "    shap_ht = shap_values_cv[mask, :]  # (n_ht_samples, n_features_non_pca)\n",
    "    X_ht = X_cv[mask].reset_index(drop=True)\n",
    "\n",
    "    if shap_ht.shape[0] == 0:\n",
    "        continue\n",
    "\n",
    "    print(f\"\\n===== HostType: {htype} =====\")\n",
    "    print(\"Samples:\", shap_ht.shape[0])\n",
    "\n",
    "    safe_htype = \"\".join(c if c.isalnum() else \"_\" for c in htype)\n",
    "\n",
    "    mean_abs_ht = np.mean(np.abs(shap_ht), axis=0)\n",
    "    shap_imp_ht = (\n",
    "        pd.DataFrame({\n",
    "            \"feature\": feature_names,\n",
    "            \"mean_abs_shap\": mean_abs_ht\n",
    "        })\n",
    "        .sort_values(\"mean_abs_shap\", ascending=False)\n",
    "    )\n",
    "\n",
    "    excel_out = os.path.join(\n",
    "        out_root,\n",
    "        f\"SHAP_importance_5fold_{safe_htype}.xlsx\"\n",
    "    )\n",
    "    shap_imp_ht.to_excel(excel_out, index=False)\n",
    "    print(\"Saved importance table to:\", excel_out)\n",
    "\n",
    "    shap_bar_df = shap_imp_ht.head(topN).iloc[::-1]\n",
    "\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    plt.barh(\n",
    "        shap_bar_df['feature'],\n",
    "        shap_bar_df['mean_abs_shap']\n",
    "    )\n",
    "    plt.xlabel(\"Mean(|SHAP value|)\")\n",
    "    plt.title(f\"SHAP Feature Importance (HostType = {htype}, top {topN})\")\n",
    "    plt.tight_layout()\n",
    "    png_bar = os.path.join(\n",
    "        out_root,\n",
    "        f\"SHAP_bar_{safe_htype}_top{topN}.png\"\n",
    "    )\n",
    "    plt.savefig(png_bar, dpi=300, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "    print(\"Saved bar plot to:\", png_bar)\n",
    "\n",
    "    plt.figure()\n",
    "    shap.summary_plot(\n",
    "        shap_ht,\n",
    "        X_ht,\n",
    "        feature_names=feature_names,\n",
    "        max_display=topN,\n",
    "        show=False,\n",
    "        cmap='coolwarm'\n",
    "    )\n",
    "    plt.tight_layout()\n",
    "    png_bee = os.path.join(\n",
    "        out_root,\n",
    "        f\"SHAP_beeswarm_{safe_htype}_top{topN}.png\"\n",
    "    )\n",
    "    plt.savefig(png_bee, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(\"Saved beeswarm plot to:\", png_bee)"
   ],
   "id": "53b99545433c77d5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 876\n",
      "Num features (with PCA): 101\n",
      "Host types: [np.str_('Cucurbit[n]uril'), np.str_('Cyclodextrin'), np.str_('MetalCage'), np.str_('OrganicCage'), np.str_('Pillar[n]arene')]\n",
      "\n",
      "===== HostType: Cucurbit[n]uril =====\n",
      "Samples: 250\n",
      "Saved importance table to: /mnt/4TBStorage1/Desktop/Papers/HostGuestModel/HostGuestModel_DataFile/BindingPrediction/ver_SupraBank/MLDeltaG/Training/Cleared3/AutoGluonModels_FineTune_MACCSKey/101Features_good_5bag_5fold_noSolvent/SHAP_ByHostType_noPCA/SHAP_importance_5fold_Cucurbit_n_uril.xlsx\n",
      "Saved bar plot to: /mnt/4TBStorage1/Desktop/Papers/HostGuestModel/HostGuestModel_DataFile/BindingPrediction/ver_SupraBank/MLDeltaG/Training/Cleared3/AutoGluonModels_FineTune_MACCSKey/101Features_good_5bag_5fold_noSolvent/SHAP_ByHostType_noPCA/SHAP_bar_Cucurbit_n_uril_top5.png\n",
      "Saved beeswarm plot to: /mnt/4TBStorage1/Desktop/Papers/HostGuestModel/HostGuestModel_DataFile/BindingPrediction/ver_SupraBank/MLDeltaG/Training/Cleared3/AutoGluonModels_FineTune_MACCSKey/101Features_good_5bag_5fold_noSolvent/SHAP_ByHostType_noPCA/SHAP_beeswarm_Cucurbit_n_uril_top5.png\n",
      "\n",
      "===== HostType: Cyclodextrin =====\n",
      "Samples: 380\n",
      "Saved importance table to: /mnt/4TBStorage1/Desktop/Papers/HostGuestModel/HostGuestModel_DataFile/BindingPrediction/ver_SupraBank/MLDeltaG/Training/Cleared3/AutoGluonModels_FineTune_MACCSKey/101Features_good_5bag_5fold_noSolvent/SHAP_ByHostType_noPCA/SHAP_importance_5fold_Cyclodextrin.xlsx\n",
      "Saved bar plot to: /mnt/4TBStorage1/Desktop/Papers/HostGuestModel/HostGuestModel_DataFile/BindingPrediction/ver_SupraBank/MLDeltaG/Training/Cleared3/AutoGluonModels_FineTune_MACCSKey/101Features_good_5bag_5fold_noSolvent/SHAP_ByHostType_noPCA/SHAP_bar_Cyclodextrin_top5.png\n",
      "Saved beeswarm plot to: /mnt/4TBStorage1/Desktop/Papers/HostGuestModel/HostGuestModel_DataFile/BindingPrediction/ver_SupraBank/MLDeltaG/Training/Cleared3/AutoGluonModels_FineTune_MACCSKey/101Features_good_5bag_5fold_noSolvent/SHAP_ByHostType_noPCA/SHAP_beeswarm_Cyclodextrin_top5.png\n",
      "\n",
      "===== HostType: MetalCage =====\n",
      "Samples: 84\n",
      "Saved importance table to: /mnt/4TBStorage1/Desktop/Papers/HostGuestModel/HostGuestModel_DataFile/BindingPrediction/ver_SupraBank/MLDeltaG/Training/Cleared3/AutoGluonModels_FineTune_MACCSKey/101Features_good_5bag_5fold_noSolvent/SHAP_ByHostType_noPCA/SHAP_importance_5fold_MetalCage.xlsx\n",
      "Saved bar plot to: /mnt/4TBStorage1/Desktop/Papers/HostGuestModel/HostGuestModel_DataFile/BindingPrediction/ver_SupraBank/MLDeltaG/Training/Cleared3/AutoGluonModels_FineTune_MACCSKey/101Features_good_5bag_5fold_noSolvent/SHAP_ByHostType_noPCA/SHAP_bar_MetalCage_top5.png\n",
      "Saved beeswarm plot to: /mnt/4TBStorage1/Desktop/Papers/HostGuestModel/HostGuestModel_DataFile/BindingPrediction/ver_SupraBank/MLDeltaG/Training/Cleared3/AutoGluonModels_FineTune_MACCSKey/101Features_good_5bag_5fold_noSolvent/SHAP_ByHostType_noPCA/SHAP_beeswarm_MetalCage_top5.png\n",
      "\n",
      "===== HostType: OrganicCage =====\n",
      "Samples: 63\n",
      "Saved importance table to: /mnt/4TBStorage1/Desktop/Papers/HostGuestModel/HostGuestModel_DataFile/BindingPrediction/ver_SupraBank/MLDeltaG/Training/Cleared3/AutoGluonModels_FineTune_MACCSKey/101Features_good_5bag_5fold_noSolvent/SHAP_ByHostType_noPCA/SHAP_importance_5fold_OrganicCage.xlsx\n",
      "Saved bar plot to: /mnt/4TBStorage1/Desktop/Papers/HostGuestModel/HostGuestModel_DataFile/BindingPrediction/ver_SupraBank/MLDeltaG/Training/Cleared3/AutoGluonModels_FineTune_MACCSKey/101Features_good_5bag_5fold_noSolvent/SHAP_ByHostType_noPCA/SHAP_bar_OrganicCage_top5.png\n",
      "Saved beeswarm plot to: /mnt/4TBStorage1/Desktop/Papers/HostGuestModel/HostGuestModel_DataFile/BindingPrediction/ver_SupraBank/MLDeltaG/Training/Cleared3/AutoGluonModels_FineTune_MACCSKey/101Features_good_5bag_5fold_noSolvent/SHAP_ByHostType_noPCA/SHAP_beeswarm_OrganicCage_top5.png\n",
      "\n",
      "===== HostType: Pillar[n]arene =====\n",
      "Samples: 99\n",
      "Saved importance table to: /mnt/4TBStorage1/Desktop/Papers/HostGuestModel/HostGuestModel_DataFile/BindingPrediction/ver_SupraBank/MLDeltaG/Training/Cleared3/AutoGluonModels_FineTune_MACCSKey/101Features_good_5bag_5fold_noSolvent/SHAP_ByHostType_noPCA/SHAP_importance_5fold_Pillar_n_arene.xlsx\n",
      "Saved bar plot to: /mnt/4TBStorage1/Desktop/Papers/HostGuestModel/HostGuestModel_DataFile/BindingPrediction/ver_SupraBank/MLDeltaG/Training/Cleared3/AutoGluonModels_FineTune_MACCSKey/101Features_good_5bag_5fold_noSolvent/SHAP_ByHostType_noPCA/SHAP_bar_Pillar_n_arene_top5.png\n",
      "Saved beeswarm plot to: /mnt/4TBStorage1/Desktop/Papers/HostGuestModel/HostGuestModel_DataFile/BindingPrediction/ver_SupraBank/MLDeltaG/Training/Cleared3/AutoGluonModels_FineTune_MACCSKey/101Features_good_5bag_5fold_noSolvent/SHAP_ByHostType_noPCA/SHAP_beeswarm_Pillar_n_arene_top5.png\n"
     ]
    }
   ],
   "execution_count": 53
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
